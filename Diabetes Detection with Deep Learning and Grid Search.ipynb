{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRANJAL\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\PRANJAL\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python :3.6.6 |Anaconda 4.4.0 (64-bit)| (default, Jun 28 2018, 11:27:44) [MSC v.1900 64 bit (AMD64)]\n",
      "Keras :2.2.0\n",
      "Numpy :1.14.3\n",
      "Pandas :0.22.0\n",
      "Matplotlib :2.2.2\n",
      "Seaborn :0.7.1\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import matplotlib\n",
    "import keras\n",
    "import sys\n",
    "import seaborn\n",
    "import sklearn\n",
    "\n",
    "print(\"Python :{}\".format(sys.version))\n",
    "print(\"Keras :{}\".format(keras.__version__))\n",
    "print(\"Numpy :{}\".format(numpy.__version__))\n",
    "print(\"Pandas :{}\".format(pandas.__version__))\n",
    "print(\"Matplotlib :{}\".format(matplotlib.__version__))\n",
    "print(\"Seaborn :{}\".format(seaborn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data from UCI repository by using url got after searching at UCI\n",
    "url=\"http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "col_names=['preg_times','glucose_concentration','blood_pressure','skin_thickness','serum_insulin',\n",
    "           'BMI','pedigree_func','age','Class']     #From info on dataset given on site\n",
    "\n",
    "#Dataset final importing\n",
    "df=pd.read_csv(url,names=col_names) #Using names of col, parameter of read_csv -> to associate data with names\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg_times</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>serum_insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_func</th>\n",
       "      <th>age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       preg_times  glucose_concentration  blood_pressure  skin_thickness  \\\n",
       "count  768.000000             768.000000      768.000000      768.000000   \n",
       "mean     3.845052             120.894531       69.105469       20.536458   \n",
       "std      3.369578              31.972618       19.355807       15.952218   \n",
       "min      0.000000               0.000000        0.000000        0.000000   \n",
       "25%      1.000000              99.000000       62.000000        0.000000   \n",
       "50%      3.000000             117.000000       72.000000       23.000000   \n",
       "75%      6.000000             140.250000       80.000000       32.000000   \n",
       "max     17.000000             199.000000      122.000000       99.000000   \n",
       "\n",
       "       serum_insulin         BMI  pedigree_func         age       Class  \n",
       "count     768.000000  768.000000     768.000000  768.000000  768.000000  \n",
       "mean       79.799479   31.992578       0.471876   33.240885    0.348958  \n",
       "std       115.244002    7.884160       0.331329   11.760232    0.476951  \n",
       "min         0.000000    0.000000       0.078000   21.000000    0.000000  \n",
       "25%         0.000000   27.300000       0.243750   24.000000    0.000000  \n",
       "50%        30.500000   32.000000       0.372500   29.000000    0.000000  \n",
       "75%       127.250000   36.600000       0.626250   41.000000    1.000000  \n",
       "max       846.000000   67.100000       2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Description\n",
    "df.describe()\n",
    "#df.shape #768 rows, 9 columns\n",
    "# Observations-\n",
    "# Minimums of several variables is zero which is not practically , thus missing values exist -> fix that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "#df[df[\"blood_pressure\"]==0]\n",
    "len(df[df[\"skin_thickness\"]==0]) # 227 values out of 768 have some issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final checking before removing useless values\n",
    "#df.head(10)\n",
    "# Unaccepted parameters with zero values = glucose_concentration,blood_pressure,skin_thickness,serum_insulin,BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg_times</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>serum_insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_func</th>\n",
       "      <th>age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.535641</td>\n",
       "      <td>12.382158</td>\n",
       "      <td>10.476982</td>\n",
       "      <td>118.775855</td>\n",
       "      <td>6.924988</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       preg_times  glucose_concentration  blood_pressure  skin_thickness  \\\n",
       "count  768.000000             763.000000      733.000000      541.000000   \n",
       "mean     3.845052             121.686763       72.405184       29.153420   \n",
       "std      3.369578              30.535641       12.382158       10.476982   \n",
       "min      0.000000              44.000000       24.000000        7.000000   \n",
       "25%      1.000000              99.000000       64.000000       22.000000   \n",
       "50%      3.000000             117.000000       72.000000       29.000000   \n",
       "75%      6.000000             141.000000       80.000000       36.000000   \n",
       "max     17.000000             199.000000      122.000000       99.000000   \n",
       "\n",
       "       serum_insulin         BMI  pedigree_func         age       Class  \n",
       "count     394.000000  757.000000     768.000000  768.000000  768.000000  \n",
       "mean      155.548223   32.457464       0.471876   33.240885    0.348958  \n",
       "std       118.775855    6.924988       0.331329   11.760232    0.476951  \n",
       "min        14.000000   18.200000       0.078000   21.000000    0.000000  \n",
       "25%        76.250000   27.500000       0.243750   24.000000    0.000000  \n",
       "50%       125.000000   32.300000       0.372500   29.000000    0.000000  \n",
       "75%       190.000000   36.600000       0.626250   41.000000    1.000000  \n",
       "max       846.000000   67.100000       2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dealing with missing values\n",
    "cols=['glucose_concentration','blood_pressure','skin_thickness','serum_insulin','BMI']\n",
    "\n",
    "# Replacing zeros with Not a number (NaN's) so that they don't harm analysis\n",
    "for col in cols:\n",
    "    df[col].replace(0,np.NaN,inplace=True)\n",
    "    \n",
    "# Checking data again\n",
    "df.describe()\n",
    "# Observed values in the right dimensions and expectations, but NaN rows are useless and don't contribute to analysis, remove them\n",
    "# serum_insulin maximum 0 value rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg_times</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>serum_insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_func</th>\n",
       "      <th>age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.301020</td>\n",
       "      <td>122.627551</td>\n",
       "      <td>70.663265</td>\n",
       "      <td>29.145408</td>\n",
       "      <td>156.056122</td>\n",
       "      <td>33.086224</td>\n",
       "      <td>0.523046</td>\n",
       "      <td>30.864796</td>\n",
       "      <td>0.331633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.211424</td>\n",
       "      <td>30.860781</td>\n",
       "      <td>12.496092</td>\n",
       "      <td>10.516424</td>\n",
       "      <td>118.841690</td>\n",
       "      <td>7.027659</td>\n",
       "      <td>0.345488</td>\n",
       "      <td>10.200777</td>\n",
       "      <td>0.471401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>76.750000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>0.269750</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>37.100000</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       preg_times  glucose_concentration  blood_pressure  skin_thickness  \\\n",
       "count  392.000000             392.000000      392.000000      392.000000   \n",
       "mean     3.301020             122.627551       70.663265       29.145408   \n",
       "std      3.211424              30.860781       12.496092       10.516424   \n",
       "min      0.000000              56.000000       24.000000        7.000000   \n",
       "25%      1.000000              99.000000       62.000000       21.000000   \n",
       "50%      2.000000             119.000000       70.000000       29.000000   \n",
       "75%      5.000000             143.000000       78.000000       37.000000   \n",
       "max     17.000000             198.000000      110.000000       63.000000   \n",
       "\n",
       "       serum_insulin         BMI  pedigree_func         age       Class  \n",
       "count     392.000000  392.000000     392.000000  392.000000  392.000000  \n",
       "mean      156.056122   33.086224       0.523046   30.864796    0.331633  \n",
       "std       118.841690    7.027659       0.345488   10.200777    0.471401  \n",
       "min        14.000000   18.200000       0.085000   21.000000    0.000000  \n",
       "25%        76.750000   28.400000       0.269750   23.000000    0.000000  \n",
       "50%       125.500000   33.200000       0.449500   27.000000    0.000000  \n",
       "75%       190.000000   37.100000       0.687000   36.000000    1.000000  \n",
       "max       846.000000   67.100000       2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing NaN rows from df\n",
    "df.dropna(inplace=True) #dropna means drop 'not a number'\n",
    "# more on dropping nana values- > https://stackoverflow.com/questions/13413590/how-to-drop-rows-of-pandas-dataframe-whose-value-in-certain-columns-is-nan\n",
    "# Describe again for final review\n",
    "df.describe()\n",
    "#Equal number of rows now for all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "# To work with Deep Learning models, we now convert the dataset to numpy array to feed to network\n",
    "#Converting dataset to numpy array\n",
    "data=df.values #returns and array\n",
    "print(data.shape)\n",
    "#As expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into input and output \n",
    "X = data[:,0:8] # to eliminate class column(excludes 8th column)\n",
    "Y = data[:,8] # includes 8th columns\n",
    "# we observe class column contains not integer values also, irrelevant for the model to classify, thus\n",
    "Y=Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
      "  2.100e+01]\n",
      " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
      "  3.300e+01]\n",
      " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
      "  2.600e+01]\n",
      " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
      "  5.300e+01]\n",
      " [1.000e+00 1.890e+02 6.000e+01 2.300e+01 8.460e+02 3.010e+01 3.980e-01\n",
      "  5.900e+01]\n",
      " [5.000e+00 1.660e+02 7.200e+01 1.900e+01 1.750e+02 2.580e+01 5.870e-01\n",
      "  5.100e+01]\n",
      " [0.000e+00 1.180e+02 8.400e+01 4.700e+01 2.300e+02 4.580e+01 5.510e-01\n",
      "  3.100e+01]\n",
      " [1.000e+00 1.030e+02 3.000e+01 3.800e+01 8.300e+01 4.330e+01 1.830e-01\n",
      "  3.300e+01]\n",
      " [1.000e+00 1.150e+02 7.000e+01 3.000e+01 9.600e+01 3.460e+01 5.290e-01\n",
      "  3.200e+01]\n",
      " [3.000e+00 1.260e+02 8.800e+01 4.100e+01 2.350e+02 3.930e+01 7.040e-01\n",
      "  2.700e+01]]\n",
      "(392, 8)\n",
      "[0 1 1 1 1 1 1 0 1 0]\n",
      "(392,)\n"
     ]
    }
   ],
   "source": [
    "# Printing to observe the final Dish\n",
    "print(X[:10])\n",
    "print(X.shape)\n",
    "print(Y[:10])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.7174265  -1.09104581 -0.37365481 ... -0.710421   -1.03187632\n",
      "  -0.9682991 ]\n",
      " [-1.02921274  0.46631407 -2.45696436 ...  1.42673006  5.11511079\n",
      "   0.2095853 ]\n",
      " [-0.09385402 -1.44794079 -1.65569146 ... -0.29723846 -0.79712575\n",
      "  -0.47751393]\n",
      " ...\n",
      " [-0.40564026 -1.12349081 -1.01467313 ... -0.66767798  0.70411863\n",
      "  -0.87014206]\n",
      " [ 2.08864966 -0.70170584  0.42761809 ... -0.02653266 -1.0202837\n",
      "   3.15429628]\n",
      " [ 0.52971846 -0.05280589  0.10710893 ... -0.9811268  -0.80582021\n",
      "  -0.0848858 ]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Observation -> Various values in the dataset have huge differences in magnitude, and that can create a bias during weight assignment \n",
    "# to particular values of particular columns, that is aproblem and due to this difference , processingg time also increases\n",
    "# Thus we scale all the values to normalize with a mean close to zero\n",
    "# Scaling the DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale=StandardScaler()\n",
    "X_normal=scale.fit_transform(X)\n",
    "print(X_normal)\n",
    "print(type(X_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg_times</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>serum_insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_func</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.021726e-17</td>\n",
       "      <td>3.129583e-17</td>\n",
       "      <td>-4.641624e-16</td>\n",
       "      <td>1.042250e-16</td>\n",
       "      <td>6.485742e-17</td>\n",
       "      <td>1.543550e-16</td>\n",
       "      <td>3.880116e-17</td>\n",
       "      <td>1.028089e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.029213e+00</td>\n",
       "      <td>-2.161731e+00</td>\n",
       "      <td>-3.739001e+00</td>\n",
       "      <td>-2.108484e+00</td>\n",
       "      <td>-1.196867e+00</td>\n",
       "      <td>-2.120941e+00</td>\n",
       "      <td>-1.269525e+00</td>\n",
       "      <td>-9.682991e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.174265e-01</td>\n",
       "      <td>-7.665958e-01</td>\n",
       "      <td>-6.941640e-01</td>\n",
       "      <td>-7.755315e-01</td>\n",
       "      <td>-6.681786e-01</td>\n",
       "      <td>-6.676780e-01</td>\n",
       "      <td>-7.340909e-01</td>\n",
       "      <td>-7.719850e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.056403e-01</td>\n",
       "      <td>-1.176959e-01</td>\n",
       "      <td>-5.314565e-02</td>\n",
       "      <td>-1.384444e-02</td>\n",
       "      <td>-2.574448e-01</td>\n",
       "      <td>1.621036e-02</td>\n",
       "      <td>-2.131475e-01</td>\n",
       "      <td>-3.793569e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.297185e-01</td>\n",
       "      <td>6.609841e-01</td>\n",
       "      <td>5.878727e-01</td>\n",
       "      <td>7.478426e-01</td>\n",
       "      <td>2.859877e-01</td>\n",
       "      <td>5.718696e-01</td>\n",
       "      <td>4.751644e-01</td>\n",
       "      <td>5.040564e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.271153e+00</td>\n",
       "      <td>2.445459e+00</td>\n",
       "      <td>3.151946e+00</td>\n",
       "      <td>3.223325e+00</td>\n",
       "      <td>5.812990e+00</td>\n",
       "      <td>4.846172e+00</td>\n",
       "      <td>5.497667e+00</td>\n",
       "      <td>4.921123e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         preg_times  glucose_concentration  blood_pressure  skin_thickness  \\\n",
       "count  3.920000e+02           3.920000e+02    3.920000e+02    3.920000e+02   \n",
       "mean  -4.021726e-17           3.129583e-17   -4.641624e-16    1.042250e-16   \n",
       "std    1.001278e+00           1.001278e+00    1.001278e+00    1.001278e+00   \n",
       "min   -1.029213e+00          -2.161731e+00   -3.739001e+00   -2.108484e+00   \n",
       "25%   -7.174265e-01          -7.665958e-01   -6.941640e-01   -7.755315e-01   \n",
       "50%   -4.056403e-01          -1.176959e-01   -5.314565e-02   -1.384444e-02   \n",
       "75%    5.297185e-01           6.609841e-01    5.878727e-01    7.478426e-01   \n",
       "max    4.271153e+00           2.445459e+00    3.151946e+00    3.223325e+00   \n",
       "\n",
       "       serum_insulin           BMI  pedigree_func           age  \n",
       "count   3.920000e+02  3.920000e+02   3.920000e+02  3.920000e+02  \n",
       "mean    6.485742e-17  1.543550e-16   3.880116e-17  1.028089e-16  \n",
       "std     1.001278e+00  1.001278e+00   1.001278e+00  1.001278e+00  \n",
       "min    -1.196867e+00 -2.120941e+00  -1.269525e+00 -9.682991e-01  \n",
       "25%    -6.681786e-01 -6.676780e-01  -7.340909e-01 -7.719850e-01  \n",
       "50%    -2.574448e-01  1.621036e-02  -2.131475e-01 -3.793569e-01  \n",
       "75%     2.859877e-01  5.718696e-01   4.751644e-01  5.040564e-01  \n",
       "max     5.812990e+00  4.846172e+00   5.497667e+00  4.921123e+00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.DataFrame(X_normal,columns=df.columns[0:8]) # Retaining the column headers\n",
    "dataset.describe()\n",
    "#Std deviation most nearly 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEEP LEARNING PACKAGES\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier # This package also has regressors, so it can be used if wanted\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_172 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 113\n",
      "Trainable params: 113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Starting defining the model-\n",
    "\n",
    "def create_model():\n",
    "    model=Sequential() # First Layer\n",
    "    model.add(Dense(8,input_dim=8,kernel_initializer='normal',activation='relu')) # First hidden layer size of dataframe\n",
    "    model.add(Dense(4,input_dim=8,kernel_initializer='normal',activation='relu')) # Second hidden layer , reduced size\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model=create_model()\n",
    "\n",
    "# Looking at our final model created\n",
    "print(model.summary())   #https://stackoverflow.com/questions/50356436/model-summary-in-keras-deep-learning-network\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n",
      "[CV]  batch_size=10, epochs=10, score=0.7251908378746673, total=   4.0s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=10, score=0.7709923664122137, total=   3.9s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=10, score=0.8230769175749558, total=   4.0s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   12.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=50, score=0.7328244229309432, total=  15.0s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   27.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=50, score=0.7709923618622408, total=  15.3s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   42.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=50, score=0.8461538415688735, total=  14.4s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   57.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=100, score=0.7175572482684186, total=  27.3s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=100, score=0.7557251871997164, total=  27.7s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=100, score=0.8230769175749558, total=  27.8s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=20, epochs=10, score=0.7557251903846973, total=   3.3s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV]  batch_size=20, epochs=10, score=0.7633587900008864, total=   3.4s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV]  batch_size=20, epochs=10, score=0.8384615457974948, total=   3.3s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV]  batch_size=20, epochs=50, score=0.7022900754258833, total=  10.3s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV]  batch_size=20, epochs=50, score=0.7709923786971405, total=  10.0s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV]  batch_size=20, epochs=50, score=0.8076923122772803, total=  10.0s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV]  batch_size=20, epochs=100, score=0.7557251901571987, total=  19.0s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV]  batch_size=20, epochs=100, score=0.7786259510134923, total=  18.8s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV]  batch_size=20, epochs=100, score=0.7923077023946322, total=  18.9s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV]  batch_size=40, epochs=10, score=0.7175572464484294, total=   2.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV]  batch_size=40, epochs=10, score=0.7633587809009407, total=   2.7s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV]  batch_size=40, epochs=10, score=0.699999988079071, total=   2.6s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV]  batch_size=40, epochs=50, score=0.7022900754258833, total=   7.7s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV]  batch_size=40, epochs=50, score=0.7786259683033893, total=   8.1s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV]  batch_size=40, epochs=50, score=0.8461538369839008, total=   8.7s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV]  batch_size=40, epochs=100, score=0.7022900936257748, total=  14.5s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV]  batch_size=40, epochs=100, score=0.7557251903846973, total=  14.3s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV]  batch_size=40, epochs=100, score=0.8307692316862253, total=  14.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7857142917963923 , using {'batch_size': 20, 'epochs': 10}\n",
      "0.7729591812406268 (0.03996033894334982) with :{'batch_size': 10, 'epochs': 10}\n",
      "0.7831632607445425 (0.04703382069004786) with :{'batch_size': 10, 'epochs': 50}\n",
      "0.765306118191505 (0.04358224628849899) with :{'batch_size': 10, 'epochs': 100}\n",
      "0.7857142917963923 (0.0372861071952023) with :{'batch_size': 20, 'epochs': 10}\n",
      "0.7602040869544964 (0.043676457630137215) with :{'batch_size': 20, 'epochs': 50}\n",
      "0.7755102061343436 (0.015087460434070294) with :{'batch_size': 20, 'epochs': 100}\n",
      "0.7270408113087926 (0.02670831713062866) with :{'batch_size': 40, 'epochs': 10}\n",
      "0.7755102054501066 (0.058735728787621615) with :{'batch_size': 40, 'epochs': 50}\n",
      "0.7627551079708703 (0.05265361568814188) with :{'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model=Sequential() # First Layer\n",
    "    model.add(Dense(8,input_dim=8,kernel_initializer='normal',activation='relu')) # First hidden layer size of dataframe\n",
    "    model.add(Dense(4,input_dim=8,kernel_initializer='normal',activation='relu')) # Second hidden layer , reduced size\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Defining a random seed to get constant values\n",
    "seed=6\n",
    "np.random.seed(seed) # With seed reset and applied of same value, everytime, results become reproducible, which otherwise,\n",
    "# would haave varied, due to chnage in seed values every time\n",
    "#dl_model=create_model\n",
    "# Creating the model with KerasClasifiers # >>>> https://keras.io/scikit-learn-api/\n",
    "model=KerasClassifier(build_fn=create_model,verbose=0)\n",
    "# The importance of verbose >>> https://stackoverflow.com/questions/47902295/what-is-the-use-of-verbose-in-keras-while-validating-the-model\n",
    "\n",
    "# Defining batch size, epochs (parameters) for grid search list\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100] #how long we train the network for,  EPOCH Info >> https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9\n",
    "\n",
    "# For using Grid Search we must convert above lists into Dictionaries\n",
    "param_grid = dict(batch_size=batch_size,epochs=epochs)   # Understanding param_grid >>http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# here, bathchsize is the parameter needed by the model, as the  keys ,and the list of values to test on, is the parameter values\n",
    "\n",
    "# Initializing and Fitting the model\n",
    "grid = GridSearchCV(estimator=model , param_grid = param_grid , cv = KFold(random_state=seed), verbose=10)\n",
    "#Default for kfold=3 thus, 1 out of 3 as test and other 2 as train\n",
    "grid_results = grid.fit(X_normal,Y)  # BOTH MUST BE NUMPY ARRAYS\n",
    "\n",
    "#Summarizing the results to make it readable\n",
    "print( \"Best : {0} , using {1}\".format(grid_results.best_score_,grid_results.best_params_))  \n",
    "# Putting 0 and 1 because multiple outputs received from both of the above \n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "std_dev = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "\n",
    "# Displaying these values for each of the combination of inputs\n",
    "for mean,stddev,param in zip(means,std_dev,params):\n",
    "    print('{0} ({1}) with :{2}'.format(mean,stddev,param))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Individual observation says, one fold(part/cut) of data is very easy to predict and the other two folds havent been that good\n",
    "# Training data is giving good results, but not testing data, which means, Overfitting problem\n",
    "# we now try to optimize our model \n",
    "# We shall now focus on optimising the learning rate and dropout rate, as the other two parameters have been optimized (atleast for the ones we tried)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.7175572514533997, total=   3.2s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.71755726146334, total=   3.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.807692303107335, total=   3.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.7251908360546782, total=   3.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   12.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.748091610788389, total=   3.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   16.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.8384615457974948, total=   3.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   19.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.1, score=0.7251908360546782, total=   3.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   22.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.1, score=0.7633587890908918, total=   3.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   25.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.1, score=0.838461541212522, total=   3.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   29.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.6641221424095504, total=   5.8s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.7633587840859216, total=   5.7s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.7846153836983901, total=   5.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.7251908360546782, total=   5.4s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.7633587900008864, total=   5.3s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.8000000027509836, total=   5.3s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.1, score=0.748091594863484, total=   5.3s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.1, score=0.7709923705071894, total=   5.5s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.1, score=0.8461538507388189, total=   5.3s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.7175572514533997, total=   5.4s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.7175572555483752, total=   5.3s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.776923078757066, total=   5.5s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.7328244256609269, total=   5.4s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.7404580211821403, total=   5.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.699999988079071, total=   5.3s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.1, score=0.6106870242657553, total=   5.4s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.1, score=0.7557251903846973, total=   5.2s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.1, score=0.8153846263885498, total=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7882653062745016 , using {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.7474489811123634 (0.04243556048075224) with :{'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.7704081670666227 (0.04884245247274631) with :{'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.7755102072747386 (0.047007743195658765) with :{'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.7372449011522897 (0.05252544251178863) with :{'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.7627551055380276 (0.030524003086167706) with :{'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.7882653062745016 (0.04183756638247275) with :{'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.737244899631763 (0.02794941769941659) with :{'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.7244897933334721 (0.017530627349477787) with :{'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.7270408202798999 (0.08595045604557942) with :{'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#Regularization technique to remove overfitting and find optimal dropout_rate and learning_rate\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Copied from above , eliminating a constant learning rate and making it a parameter to the create_model function\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model=Sequential() \n",
    "    model.add(Dense(8,input_dim=8,kernel_initializer='normal',activation='relu')) \n",
    "    model.add(Dropout(dropout_rate)) #>>https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "    model.add(Dense(4,input_dim=8,kernel_initializer='normal',activation='relu')) \n",
    "    model.add(Dropout(dropout_rate)) # 2 layers for both the hidden layers\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    adam=Adam(learning_rate)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Defining a random seed to get constant values\n",
    "seed=6\n",
    "np.random.seed(seed) # With seed reset and applied of same value, everytime, results become reproducible, which otherwise,\n",
    "# would haave varied, due to chnage in seed values every time\n",
    "\n",
    "model=KerasClassifier(build_fn=create_model,epochs = 10,batch_size = 20,verbose=0) # From results above\n",
    "\n",
    "# Change in gris search parameters this time\n",
    "learning_rate=[0.001,0.01,0.1]  # A little below, a little above and the last one to genuinely compare the results, determines how fast and slow we remove errors\n",
    "dropout_rate=[0.0,0.1,0.2] # cant be greater than 0.2 disrupts the system\n",
    "\n",
    "# For using Grid Search we must convert above lists into Dictionaries\n",
    "param_grid = dict(learning_rate=learning_rate,dropout_rate=dropout_rate)   # Understanding param_grid >>http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# here, bathchsize is the parameter needed by the model, as the  keys ,and the list of values to test on, is the parameter values\n",
    "\n",
    "# Initializing and Fitting the model\n",
    "grid = GridSearchCV(estimator=model , param_grid = param_grid , cv = KFold(random_state=seed), verbose=10)\n",
    "#Default for kfold=3 thus, 1 out of 3 as test and other 2 as train\n",
    "grid_results = grid.fit(X_normal,Y) \n",
    "\n",
    "#Summarizing the results to make it readable\n",
    "print( \"Best : {0} , using {1}\".format(grid_results.best_score_,grid_results.best_params_))  \n",
    "# Putting 0 and 1 because multiple outputs received from both of the above \n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "std_dev = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "\n",
    "# Displaying these values for each of the combination of inputs\n",
    "for mean,stddev,param in zip(means,std_dev,params):\n",
    "    print('{0} ({1}) with :{2}'.format(mean,stddev,param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Noting down the best learning_rate and dropout_rate \n",
    "#: Best : 0.7882653062745016 ,\n",
    "#using {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
    "\n",
    "# Now we can try to make some changes to kernel_initilaizer and activations, number of neurons \n",
    "#to improve and create better models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] activation=softmax, init=uniform ................................\n",
      "[CV]  activation=softmax, init=uniform, score=0.7251908442446293, total=   4.2s\n",
      "[CV] activation=softmax, init=uniform ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=uniform, score=0.7633587900008864, total=   4.2s\n",
      "[CV] activation=softmax, init=uniform ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=uniform, score=0.8538461556801429, total=   3.8s\n",
      "[CV] activation=softmax, init=normal .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   12.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=normal, score=0.732824433850878, total=   4.5s\n",
      "[CV] activation=softmax, init=normal .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   17.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=normal, score=0.778625960113438, total=   4.6s\n",
      "[CV] activation=softmax, init=normal .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   22.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=normal, score=0.838461541212522, total=   4.5s\n",
      "[CV] activation=softmax, init=zero ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   26.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=zero, score=0.7022900663259375, total=   3.7s\n",
      "[CV] activation=softmax, init=zero ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   30.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=zero, score=0.8015267289321841, total=   3.8s\n",
      "[CV] activation=softmax, init=zero ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   34.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=zero, score=0.8000000027509836, total=   3.8s\n",
      "[CV] activation=relu, init=uniform ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   38.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, init=uniform, score=0.7328244247509323, total=   4.7s\n",
      "[CV] activation=relu, init=uniform ...................................\n",
      "[CV]  activation=relu, init=uniform, score=0.7709923796071351, total=   4.7s\n",
      "[CV] activation=relu, init=uniform ...................................\n",
      "[CV]  activation=relu, init=uniform, score=0.8615384697914124, total=   4.7s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV]  activation=relu, init=normal, score=0.7099236600271618, total=   5.4s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV]  activation=relu, init=normal, score=0.7633587931858674, total=   5.5s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV]  activation=relu, init=normal, score=0.7307692307692307, total=   5.4s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV]  activation=relu, init=zero, score=0.6106870242657553, total=   5.4s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV]  activation=relu, init=zero, score=0.6946564958295749, total=   5.3s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV]  activation=relu, init=zero, score=0.699999988079071, total=   5.4s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV]  activation=tanh, init=uniform, score=0.7328244379458536, total=   4.3s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV]  activation=tanh, init=uniform, score=0.7862595397097464, total=   4.1s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV]  activation=tanh, init=uniform, score=0.7846153836983901, total=   4.1s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV]  activation=tanh, init=normal, score=0.7328244438608185, total=   4.8s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV]  activation=tanh, init=normal, score=0.778625960113438, total=   4.8s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV]  activation=tanh, init=normal, score=0.7846153791134174, total=   4.9s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV]  activation=tanh, init=zero, score=0.6106870242657553, total=   4.0s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV]  activation=tanh, init=zero, score=0.6946564958295749, total=   4.0s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV]  activation=tanh, init=zero, score=0.699999988079071, total=   4.2s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV]  activation=linear, init=uniform, score=0.7404580243671214, total=   3.8s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV]  activation=linear, init=uniform, score=0.7709923796071351, total=   3.9s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV]  activation=linear, init=uniform, score=0.8230769313298739, total=   4.1s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV]  activation=linear, init=normal, score=0.7709923645922245, total=   4.5s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV]  activation=linear, init=normal, score=0.7557252003946378, total=   4.5s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV]  activation=linear, init=normal, score=0.8153846218035772, total=   4.7s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV]  activation=linear, init=zero, score=0.6106870242657553, total=   3.7s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV]  activation=linear, init=zero, score=0.6946564958295749, total=   4.0s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV]  activation=linear, init=zero, score=0.699999988079071, total=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7882653123566082 , using {'activation': 'relu', 'init': 'uniform'}\n",
      "0.7806122508280131 (0.053893879313633306) with :{'activation': 'softmax', 'init': 'uniform'}\n",
      "0.7831632703238603 (0.043218050551739946) with :{'activation': 'softmax', 'init': 'normal'}\n",
      "0.7678571442256168 (0.04645583435004437) with :{'activation': 'softmax', 'init': 'zero'}\n",
      "0.7882653123566082 (0.053920346663262994) with :{'activation': 'relu', 'init': 'uniform'}\n",
      "0.7346938810482317 (0.02201686217545363) with :{'activation': 'relu', 'init': 'normal'}\n",
      "0.6683673458744068 (0.040922317011154695) with :{'activation': 'relu', 'init': 'zero'}\n",
      "0.7678571452899855 (0.024828338316107586) with :{'activation': 'tanh', 'init': 'uniform'}\n",
      "0.7653061280749283 (0.0231413533523325) with :{'activation': 'tanh', 'init': 'normal'}\n",
      "0.6683673458744068 (0.040922317011154695) with :{'activation': 'tanh', 'init': 'zero'}\n",
      "0.7780612346773245 (0.034077259567500455) with :{'activation': 'linear', 'init': 'uniform'}\n",
      "0.7806122496115918 (0.025276289258117472) with :{'activation': 'linear', 'init': 'normal'}\n",
      "0.6683673458744068 (0.040922317011154695) with :{'activation': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# Changing the kernel_initializers, activation functions and hardcode the ones will already know beforehand\n",
    "# Defining a random seed to get constant values\n",
    "seed=6\n",
    "np.random.seed(seed) \n",
    "\n",
    "\n",
    "def create_model(activation,init):\n",
    "    model=Sequential() \n",
    "    model.add(Dense(8,input_dim=8,kernel_initializer=init,activation=activation)) \n",
    "    model.add(Dropout(rate=0.1)) #>>https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "    model.add(Dense(4,input_dim=8,kernel_initializer=init,activation=activation)) \n",
    "    model.add(Dropout(rate=0.1)) # 2 layers for both the hidden layers\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #Compilation step\n",
    "    adam=Adam(lr=0.1)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model=KerasClassifier(build_fn=create_model,epochs = 10,batch_size = 20,verbose=0) # From results above\n",
    "\n",
    "# Change in gris search parameters this time\n",
    "activation = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# For using Grid Search we must convert above lists into Dictionaries\n",
    "param_grid = dict(activation=activation,init=init)   \n",
    "\n",
    "# Initializing and Fitting the model\n",
    "grid = GridSearchCV(estimator=model , param_grid = param_grid , cv = KFold(random_state=seed), verbose=10)\n",
    "#Default for kfold=3 thus, 1 out of 3 as test and other 2 as train\n",
    "grid_results = grid.fit(X_normal,Y) \n",
    "\n",
    "#Summarizing the results to make it readable\n",
    "print( \"Best : {0} , using {1}\".format(grid_results.best_score_,grid_results.best_params_))  \n",
    "# Putting 0 and 1 because multiple outputs received from both of the above \n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "std_dev = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "\n",
    "# Displaying these values for each of the combination of inputs\n",
    "for mean,stddev,param in zip(means,std_dev,params):\n",
    "    print('{0} ({1}) with :{2}'.format(mean,stddev,param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n",
      "[CV] .... neuron1=4, neuron2=2, score=0.740458014357181, total=   3.5s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=2, score=0.748091610788389, total=   3.4s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=2, score=0.8461538507388189, total=   3.3s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   10.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=4, score=0.7328244247509323, total=   3.9s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   14.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=4, score=0.6946564958295749, total=   3.9s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   18.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=4, score=0.699999988079071, total=   3.8s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   22.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=8, score=0.7328244347608727, total=   4.5s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   27.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=8, score=0.7557252003946378, total=   4.5s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   32.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=8, score=0.8153846218035772, total=   4.5s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   36.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=8, neuron2=2, score=0.740458014357181, total=   4.5s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ... neuron1=8, neuron2=2, score=0.7557252003946378, total=   4.3s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ... neuron1=8, neuron2=2, score=0.7538461685180664, total=   4.2s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ... neuron1=8, neuron2=4, score=0.7175572464484294, total=   4.7s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ... neuron1=8, neuron2=4, score=0.7862595497196867, total=   4.6s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ... neuron1=8, neuron2=4, score=0.6769230686701261, total=   4.6s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ... neuron1=8, neuron2=8, score=0.7328244438608185, total=   5.4s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ... neuron1=8, neuron2=8, score=0.7862595588196325, total=   5.4s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] .... neuron1=8, neuron2=8, score=0.838461541212522, total=   5.4s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ... neuron1=16, neuron2=2, score=0.709923665032132, total=   5.9s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=2, score=0.7557251903846973, total=   6.1s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=2, score=0.8153846263885498, total=   6.5s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=4, score=0.7175572455384349, total=   6.8s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=4, score=0.7709923786971405, total=   6.4s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=4, score=0.8076923076923077, total=   6.3s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=8, score=0.7251908392396592, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=8, score=0.7480916098783944, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=8, score=0.8615384560364944, total=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7857142977264463 , using {'neuron1': 8, 'neuron2': 8}\n",
      "0.7780612282911126 (0.04806602116399805) with :{'neuron1': 4, 'neuron2': 2}\n",
      "0.7091836710365451 (0.01688981817576688) with :{'neuron1': 4, 'neuron2': 4}\n",
      "0.7678571506118288 (0.034762611285084774) with :{'neuron1': 4, 'neuron2': 8}\n",
      "0.7500000077546859 (0.0068034509266060314) with :{'neuron1': 8, 'neuron2': 2}\n",
      "0.7270408143498459 (0.04511077242223102) with :{'neuron1': 8, 'neuron2': 4}\n",
      "0.7857142977264463 (0.04310006652941386) with :{'neuron1': 8, 'neuron2': 8}\n",
      "0.7602040854339697 (0.04314332151908581) with :{'neuron1': 16, 'neuron2': 2}\n",
      "0.7653061244256643 (0.036993737680639446) with :{'neuron1': 16, 'neuron2': 4}\n",
      "0.7780612247939013 (0.05954206467217088) with :{'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "# working on changing the number of neurons\n",
    "# Defining a random seed to get constant values\n",
    "seed=6\n",
    "np.random.seed(seed) \n",
    "\n",
    "\n",
    "def create_model(neuron1,neuron2):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(neuron1,input_dim=8,kernel_initializer='uniform',activation='relu')) \n",
    "    model.add(Dropout(rate=0.1)) #>>https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "    model.add(Dense(neuron2,input_dim=neuron1,kernel_initializer='uniform',activation='relu')) \n",
    "    model.add(Dropout(rate=0.1)) # 2 layers for both the hidden layers\n",
    "    model.add(Dense(1,activation='sigmoid')) #Always keep sigmoid here\n",
    "    #Compilation step\n",
    "    adam=Adam(lr=0.1)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model=KerasClassifier(build_fn=create_model,epochs = 10,batch_size = 20,verbose=0) # From results above\n",
    "\n",
    "# Change in gris search parameters this time\n",
    "neuron1=[4,8,16]\n",
    "neuron2=[2,4,8]\n",
    "\n",
    "# For using Grid Search we must convert above lists into Dictionaries\n",
    "param_grid = dict(neuron1=neuron1,neuron2=neuron2)   \n",
    "\n",
    "# Initializing and Fitting the model\n",
    "grid = GridSearchCV(estimator=model , param_grid = param_grid , cv = KFold(random_state=seed), verbose=10,refit = True)\n",
    "# Refit here tells the model to train the data based on the best  parameters we have found till now and the ones that are going to be found now\n",
    "#Default for kfold=3 thus, 1 out of 3 as test and other 2 as train\n",
    "grid_results = grid.fit(X_normal,Y) \n",
    "\n",
    "#Summarizing the results to make it readable\n",
    "print( \"Best : {0} , using {1}\".format(grid_results.best_score_,grid_results.best_params_))  \n",
    "# Putting 0 and 1 because multiple outputs received from both of the above \n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "std_dev = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "\n",
    "# Displaying these values for each of the combination of inputs\n",
    "for mean,stddev,param in zip(means,std_dev,params):\n",
    "    print('{0} ({1}) with :{2}'.format(mean,stddev,param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating predictions now-\n",
    "y_pred = grid.predict(X_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 1)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8188775510204082\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.92      0.87       262\n",
      "          1       0.80      0.61      0.69       130\n",
      "\n",
      "avg / total       0.82      0.82      0.81       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finally generating a classification report and the accuracy score\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "print(accuracy_score(Y,y_pred))\n",
    "print(classification_report(Y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preg_times                 0.000\n",
      "glucose_concentration    137.000\n",
      "blood_pressure            40.000\n",
      "skin_thickness            35.000\n",
      "serum_insulin            168.000\n",
      "BMI                       43.100\n",
      "pedigree_func              2.288\n",
      "age                       33.000\n",
      "Class                      1.000\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Example Datapoint\n",
    "example=df.iloc[1]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRANJAL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Making a predcition\n",
    "print(grid.predict(example[:8].reshape([1,-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# End comments\n",
    "# Could have done something with KFold ,values could have been varied and observed\n",
    "# Add more layers in the model, and better combinations with more parameters to optimize together, not individually\n",
    "# Seeds can be changed, but thats not so probable to be effective"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
